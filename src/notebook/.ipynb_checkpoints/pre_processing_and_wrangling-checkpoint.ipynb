{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder. \\\n",
    "    appName(\"pyspark-1\"). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create data schema "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some failures, I decided not to use a schema, read below for details, or jump to \n",
    "[Pivot](#Pivot) where I'm modifying columns post inferSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType,IntegerType,StructField,StructType,DateType,FloatType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_required_feaures for the following required features\n",
    "\n",
    "- Agency - string\n",
    "- Job Category - string\n",
    "- Salary Range From - float\n",
    "- Salary Range To - float\n",
    "- Salary Frequency - string\n",
    "- Minimum Qual Requirements - string\n",
    "- Posting Date - should be a date but importing as a string - see [data exploration](./data_exploration.ipynb) for details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Job ID',\n",
       " 'Agency',\n",
       " 'Posting Type',\n",
       " '# Of Positions',\n",
       " 'Business Title',\n",
       " 'Civil Service Title',\n",
       " 'Title Code No',\n",
       " 'Level',\n",
       " 'Job Category',\n",
       " 'Full-Time/Part-Time indicator',\n",
       " 'Salary Range From',\n",
       " 'Salary Range To',\n",
       " 'Salary Frequency',\n",
       " 'Work Location',\n",
       " 'Division/Work Unit',\n",
       " 'Job Description',\n",
       " 'Minimum Qual Requirements',\n",
       " 'Preferred Skills',\n",
       " 'Additional Information',\n",
       " 'To Apply',\n",
       " 'Hours/Shift',\n",
       " 'Work Location 1',\n",
       " 'Recruitment Contact',\n",
       " 'Residency Requirement',\n",
       " 'Posting Date',\n",
       " 'Post Until',\n",
       " 'Posting Updated',\n",
       " 'Process Date']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv(\"/dataset/nyc-jobs.csv\", header=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructField(\"Job ID\", StringType(), True),\n",
      "StructField(\"Agency\", StringType(), True),\n",
      "StructField(\"Posting Type\", StringType(), True),\n",
      "StructField(\"# Of Positions\", StringType(), True),\n",
      "StructField(\"Business Title\", StringType(), True),\n",
      "StructField(\"Civil Service Title\", StringType(), True),\n",
      "StructField(\"Title Code No\", StringType(), True),\n",
      "StructField(\"Level\", StringType(), True),\n",
      "StructField(\"Job Category\", StringType(), True),\n",
      "StructField(\"Full-Time/Part-Time indicator\", StringType(), True),\n",
      "StructField(\"Salary Range From\", StringType(), True),\n",
      "StructField(\"Salary Range To\", StringType(), True),\n",
      "StructField(\"Salary Frequency\", StringType(), True),\n",
      "StructField(\"Work Location\", StringType(), True),\n",
      "StructField(\"Division/Work Unit\", StringType(), True),\n",
      "StructField(\"Job Description\", StringType(), True),\n",
      "StructField(\"Minimum Qual Requirements\", StringType(), True),\n",
      "StructField(\"Preferred Skills\", StringType(), True),\n",
      "StructField(\"Additional Information\", StringType(), True),\n",
      "StructField(\"To Apply\", StringType(), True),\n",
      "StructField(\"Hours/Shift\", StringType(), True),\n",
      "StructField(\"Work Location 1\", StringType(), True),\n",
      "StructField(\"Recruitment Contact\", StringType(), True),\n",
      "StructField(\"Residency Requirement\", StringType(), True),\n",
      "StructField(\"Posting Date\", StringType(), True),\n",
      "StructField(\"Post Until\", StringType(), True),\n",
      "StructField(\"Posting Updated\", StringType(), True),\n",
      "StructField(\"Process Date\", StringType(), True),\n"
     ]
    }
   ],
   "source": [
    "for c in df.columns:\n",
    "    print(f'StructField(\"{c}\", StringType(), True),')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "copy the output and change the types as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "myc_jobs_schema = StructType(fields=[StructField(\"Job ID\", StringType(), True),\n",
    "                                    StructField(\"Agency\", StringType(), True),\n",
    "                                    StructField(\"Posting Type\", StringType(), True),\n",
    "                                    StructField(\"# Of Positions\", StringType(), True),\n",
    "                                    StructField(\"Business Title\", StringType(), True),\n",
    "                                    StructField(\"Civil Service Title\", StringType(), True),\n",
    "                                    StructField(\"Title Code No\", StringType(), True),\n",
    "                                    StructField(\"Level\", StringType(), True),\n",
    "                                    StructField(\"Job Category\", StringType(), True),\n",
    "                                    StructField(\"Full-Time/Part-Time indicator\", StringType(), True),\n",
    "                                    StructField(\"Salary Range From\", FloatType(), True),\n",
    "                                    StructField(\"Salary Range To\", FloatType(), True),\n",
    "                                    StructField(\"Salary Frequency\", StringType(), True),\n",
    "                                    StructField(\"Work Location\", StringType(), True),\n",
    "                                    StructField(\"Division/Work Unit\", StringType(), True),\n",
    "                                    StructField(\"Job Description\", StringType(), True),\n",
    "                                    StructField(\"Minimum Qual Requirements\", StringType(), True),\n",
    "                                    StructField(\"Preferred Skills\", StringType(), True),\n",
    "                                    StructField(\"Additional Information\", StringType(), True),\n",
    "                                    StructField(\"To Apply\", StringType(), True),\n",
    "                                    StructField(\"Hours/Shift\", StringType(), True),\n",
    "                                    StructField(\"Work Location 1\", StringType(), True),\n",
    "                                    StructField(\"Recruitment Contact\", StringType(), True),\n",
    "                                    StructField(\"Residency Requirement\", StringType(), True),\n",
    "                                    StructField(\"Posting Date\", DateType(), True),\n",
    "                                    StructField(\"Post Until\", StringType(), True),\n",
    "                                    StructField(\"Posting Updated\", DateType(), True),\n",
    "                                    StructField(\"Process Date\", DateType(), True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_types = spark.read.schema(myc_jobs_schema).csv(\"/dataset/nyc-jobs.csv\", header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Job ID: string (nullable = true)\n",
      " |-- Agency: string (nullable = true)\n",
      " |-- Posting Type: string (nullable = true)\n",
      " |-- # Of Positions: string (nullable = true)\n",
      " |-- Business Title: string (nullable = true)\n",
      " |-- Civil Service Title: string (nullable = true)\n",
      " |-- Title Code No: string (nullable = true)\n",
      " |-- Level: string (nullable = true)\n",
      " |-- Job Category: string (nullable = true)\n",
      " |-- Full-Time/Part-Time indicator: string (nullable = true)\n",
      " |-- Salary Range From: float (nullable = true)\n",
      " |-- Salary Range To: float (nullable = true)\n",
      " |-- Salary Frequency: string (nullable = true)\n",
      " |-- Work Location: string (nullable = true)\n",
      " |-- Division/Work Unit: string (nullable = true)\n",
      " |-- Job Description: string (nullable = true)\n",
      " |-- Minimum Qual Requirements: string (nullable = true)\n",
      " |-- Preferred Skills: string (nullable = true)\n",
      " |-- Additional Information: string (nullable = true)\n",
      " |-- To Apply: string (nullable = true)\n",
      " |-- Hours/Shift: string (nullable = true)\n",
      " |-- Work Location 1: string (nullable = true)\n",
      " |-- Recruitment Contact: string (nullable = true)\n",
      " |-- Residency Requirement: string (nullable = true)\n",
      " |-- Posting Date: date (nullable = true)\n",
      " |-- Post Until: string (nullable = true)\n",
      " |-- Posting Updated: date (nullable = true)\n",
      " |-- Process Date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_types.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job ID</th>\n",
       "      <td>2946</td>\n",
       "      <td>384821.5631364562</td>\n",
       "      <td>53075.33897715407</td>\n",
       "      <td>132292</td>\n",
       "      <td>97899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agency</th>\n",
       "      <td>2946</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ADMIN FOR CHILDREN'S SVCS</td>\n",
       "      <td>TEACHERS RETIREMENT SYSTEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Posting Type</th>\n",
       "      <td>2946</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>External</td>\n",
       "      <td>Internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># Of Positions</th>\n",
       "      <td>2946</td>\n",
       "      <td>2.4959266802443993</td>\n",
       "      <td>9.281312826466838</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Title</th>\n",
       "      <td>2946</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>.NET DEVELOPER</td>\n",
       "      <td>executive Vice President for Operations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Civil Service Title</th>\n",
       "      <td>2946</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ACCOUNTANT</td>\n",
       "      <td>YOUTH COORDINATOR (YOUTH SERVI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title Code No</th>\n",
       "      <td>2946</td>\n",
       "      <td>35558.51334552102</td>\n",
       "      <td>28141.297679769723</td>\n",
       "      <td>0527A</td>\n",
       "      <td>95841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Level</th>\n",
       "      <td>2946</td>\n",
       "      <td>1.0531400966183575</td>\n",
       "      <td>1.1403671232078134</td>\n",
       "      <td>0</td>\n",
       "      <td>M7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Category</th>\n",
       "      <td>2944</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Administration &amp; Human Resources</td>\n",
       "      <td>Technology, Data &amp; Innovation Social Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full-Time/Part-Time indicator</th>\n",
       "      <td>2751</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salary Range From</th>\n",
       "      <td>2946</td>\n",
       "      <td>58904.13979079751</td>\n",
       "      <td>26986.57593162361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>218587.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salary Range To</th>\n",
       "      <td>2946</td>\n",
       "      <td>85535.71163649892</td>\n",
       "      <td>42871.313462465856</td>\n",
       "      <td>10.36</td>\n",
       "      <td>234402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salary Frequency</th>\n",
       "      <td>2946</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Annual</td>\n",
       "      <td>Hourly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Work Location</th>\n",
       "      <td>2946</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1 Bay St., S.I.,Ny</td>\n",
       "      <td>Â Tort: Bronx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Division/Work Unit</th>\n",
       "      <td>2946</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10th Precinct - Civilian/Cadet</td>\n",
       "      <td>Zoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Description</th>\n",
       "      <td>2946</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>\"NOTE: IT IS IMPORTANT THAT CANDIDATES MUST HA...</td>\n",
       "      <td>â€¢ Under supervision, perform all types of wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minimum Qual Requirements</th>\n",
       "      <td>2928</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>â€¢ The candidate will be expected to gain a...</td>\n",
       "      <td>â€¢ Masterâ€™s degree in business administrati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Preferred Skills</th>\n",
       "      <td>2687</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>â€¢ Performs other related assignments or s...</td>\n",
       "      <td>â€¢The Deputy Chief is expected to be a strate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Additional Information</th>\n",
       "      <td>2383</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>or  \"\"3\"\"  above.  However</td>\n",
       "      <td>â€œNOTE: This position is open to qualified pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>To Apply</th>\n",
       "      <td>2766</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>\"\"2\"\"</td>\n",
       "      <td>â€¢Extensive experience with CommVault Simpana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hours/Shift</th>\n",
       "      <td>1884</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>\"\"2\"\"</td>\n",
       "      <td>â€¢General knowledge of NYC hiring practices. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Work Location 1</th>\n",
       "      <td>1808</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>\"\"2\"\"</td>\n",
       "      <td>â€¢Knowledge of statistics and experience usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recruitment Contact</th>\n",
       "      <td>1183</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Environmental Health</td>\n",
       "      <td>â€¢ Strong written and verbal communication sk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residency Requirement</th>\n",
       "      <td>2268</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>executive or supervisory capacity. The super...</td>\n",
       "      <td>â€œNOTE: This position is open to qualified pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Post Until</th>\n",
       "      <td>1447</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>\"\"2\"\"</td>\n",
       "      <td>â€¢ Demonstrated ability to manage the design ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0                   1                   2  \\\n",
       "summary                        count                mean              stddev   \n",
       "Job ID                          2946   384821.5631364562   53075.33897715407   \n",
       "Agency                          2946                None                None   \n",
       "Posting Type                    2946                None                None   \n",
       "# Of Positions                  2946  2.4959266802443993   9.281312826466838   \n",
       "Business Title                  2946                None                None   \n",
       "Civil Service Title             2946                None                None   \n",
       "Title Code No                   2946   35558.51334552102  28141.297679769723   \n",
       "Level                           2946  1.0531400966183575  1.1403671232078134   \n",
       "Job Category                    2944                None                None   \n",
       "Full-Time/Part-Time indicator   2751                None                None   \n",
       "Salary Range From               2946   58904.13979079751   26986.57593162361   \n",
       "Salary Range To                 2946   85535.71163649892  42871.313462465856   \n",
       "Salary Frequency                2946                None                None   \n",
       "Work Location                   2946                None                None   \n",
       "Division/Work Unit              2946                None                None   \n",
       "Job Description                 2946                None                None   \n",
       "Minimum Qual Requirements       2928                None                None   \n",
       "Preferred Skills                2687                None                None   \n",
       "Additional Information          2383                None                None   \n",
       "To Apply                        2766                None                None   \n",
       "Hours/Shift                     1884                None                None   \n",
       "Work Location 1                 1808                None                None   \n",
       "Recruitment Contact             1183                None                None   \n",
       "Residency Requirement           2268                None                None   \n",
       "Post Until                      1447                None                None   \n",
       "\n",
       "                                                                               3  \\\n",
       "summary                                                                      min   \n",
       "Job ID                                                                    132292   \n",
       "Agency                                                 ADMIN FOR CHILDREN'S SVCS   \n",
       "Posting Type                                                            External   \n",
       "# Of Positions                                                                 1   \n",
       "Business Title                                                    .NET DEVELOPER   \n",
       "Civil Service Title                                                   ACCOUNTANT   \n",
       "Title Code No                                                              0527A   \n",
       "Level                                                                          0   \n",
       "Job Category                                    Administration & Human Resources   \n",
       "Full-Time/Part-Time indicator                                                  F   \n",
       "Salary Range From                                                            0.0   \n",
       "Salary Range To                                                            10.36   \n",
       "Salary Frequency                                                          Annual   \n",
       "Work Location                                                 1 Bay St., S.I.,Ny   \n",
       "Division/Work Unit                                10th Precinct - Civilian/Cadet   \n",
       "Job Description                \"NOTE: IT IS IMPORTANT THAT CANDIDATES MUST HA...   \n",
       "Minimum Qual Requirements        â€¢ The candidate will be expected to gain a...   \n",
       "Preferred Skills                  â€¢ Performs other related assignments or s...   \n",
       "Additional Information                                or  \"\"3\"\"  above.  However   \n",
       "To Apply                                                                   \"\"2\"\"   \n",
       "Hours/Shift                                                                \"\"2\"\"   \n",
       "Work Location 1                                                            \"\"2\"\"   \n",
       "Recruitment Contact                                         Environmental Health   \n",
       "Residency Requirement            executive or supervisory capacity. The super...   \n",
       "Post Until                                                                 \"\"2\"\"   \n",
       "\n",
       "                                                                               4  \n",
       "summary                                                                      max  \n",
       "Job ID                                                                     97899  \n",
       "Agency                                                TEACHERS RETIREMENT SYSTEM  \n",
       "Posting Type                                                            Internal  \n",
       "# Of Positions                                                                91  \n",
       "Business Title                           executive Vice President for Operations  \n",
       "Civil Service Title                               YOUTH COORDINATOR (YOUTH SERVI  \n",
       "Title Code No                                                              95841  \n",
       "Level                                                                         M7  \n",
       "Job Category                       Technology, Data & Innovation Social Services  \n",
       "Full-Time/Part-Time indicator                                                  P  \n",
       "Salary Range From                                                       218587.0  \n",
       "Salary Range To                                                         234402.0  \n",
       "Salary Frequency                                                          Hourly  \n",
       "Work Location                                                      Â Tort: Bronx  \n",
       "Division/Work Unit                                                        Zoning  \n",
       "Job Description                â€¢ Under supervision, perform all types of wo...  \n",
       "Minimum Qual Requirements      â€¢ Masterâ€™s degree in business administrati...  \n",
       "Preferred Skills               â€¢The Deputy Chief is expected to be a strate...  \n",
       "Additional Information         â€œNOTE: This position is open to qualified pe...  \n",
       "To Apply                       â€¢Extensive experience with CommVault Simpana...  \n",
       "Hours/Shift                    â€¢General knowledge of NYC hiring practices. ...  \n",
       "Work Location 1                â€¢Knowledge of statistics and experience usin...  \n",
       "Recruitment Contact            â€¢ Strong written and verbal communication sk...  \n",
       "Residency Requirement          â€œNOTE: This position is open to qualified pe...  \n",
       "Post Until                     â€¢ Demonstrated ability to manage the design ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_types.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job ID</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Posting Type</th>\n",
       "      <th># Of Positions</th>\n",
       "      <th>Business Title</th>\n",
       "      <th>Civil Service Title</th>\n",
       "      <th>Title Code No</th>\n",
       "      <th>Level</th>\n",
       "      <th>Job Category</th>\n",
       "      <th>Full-Time/Part-Time indicator</th>\n",
       "      <th>...</th>\n",
       "      <th>Additional Information</th>\n",
       "      <th>To Apply</th>\n",
       "      <th>Hours/Shift</th>\n",
       "      <th>Work Location 1</th>\n",
       "      <th>Recruitment Contact</th>\n",
       "      <th>Residency Requirement</th>\n",
       "      <th>Posting Date</th>\n",
       "      <th>Post Until</th>\n",
       "      <th>Posting Updated</th>\n",
       "      <th>Process Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97899</td>\n",
       "      <td>DEPARTMENT OF BUSINESS SERV.</td>\n",
       "      <td>Internal</td>\n",
       "      <td>1</td>\n",
       "      <td>EXECUTIVE DIRECTOR, BUSINESS DEVELOPMENT</td>\n",
       "      <td>ADMINISTRATIVE BUSINESS PROMOT</td>\n",
       "      <td>10009</td>\n",
       "      <td>M3</td>\n",
       "      <td>None</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>In addition to applying through this website, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>New York City residency is generally required ...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>None</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>2019-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>133921</td>\n",
       "      <td>NYC HOUSING AUTHORITY</td>\n",
       "      <td>Internal</td>\n",
       "      <td>50</td>\n",
       "      <td>Temporary Painter</td>\n",
       "      <td>PAINTER</td>\n",
       "      <td>91830</td>\n",
       "      <td>0</td>\n",
       "      <td>Maintenance &amp; Operations</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>SPECIAL NOTE:    1.  This is a temporary assig...</td>\n",
       "      <td>\"Click the \"\"Apply Now\"\" button.\"</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NYCHA has no residency requirement.</td>\n",
       "      <td>2014-01-09</td>\n",
       "      <td>None</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>2019-12-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Job ID                        Agency Posting Type # Of Positions  \\\n",
       "0    None                          None         None           None   \n",
       "1   97899  DEPARTMENT OF BUSINESS SERV.     Internal              1   \n",
       "2    None                          None         None           None   \n",
       "3    None                          None         None           None   \n",
       "4  133921         NYC HOUSING AUTHORITY     Internal             50   \n",
       "\n",
       "                             Business Title             Civil Service Title  \\\n",
       "0                                      None                            None   \n",
       "1  EXECUTIVE DIRECTOR, BUSINESS DEVELOPMENT  ADMINISTRATIVE BUSINESS PROMOT   \n",
       "2                                      None                            None   \n",
       "3                                      None                            None   \n",
       "4                         Temporary Painter                         PAINTER   \n",
       "\n",
       "  Title Code No Level              Job Category Full-Time/Part-Time indicator  \\\n",
       "0          None  None                      None                          None   \n",
       "1         10009    M3                      None                             F   \n",
       "2          None  None                      None                          None   \n",
       "3          None  None                      None                          None   \n",
       "4         91830     0  Maintenance & Operations                             F   \n",
       "\n",
       "   ...                             Additional Information  \\\n",
       "0  ...                                               None   \n",
       "1  ...                                               None   \n",
       "2  ...                                               None   \n",
       "3  ...                                               None   \n",
       "4  ...  SPECIAL NOTE:    1.  This is a temporary assig...   \n",
       "\n",
       "                                            To Apply Hours/Shift  \\\n",
       "0                                               None        None   \n",
       "1  In addition to applying through this website, ...        None   \n",
       "2                                               None        None   \n",
       "3                                               None        None   \n",
       "4                  \"Click the \"\"Apply Now\"\" button.\"        None   \n",
       "\n",
       "  Work Location 1 Recruitment Contact  \\\n",
       "0            None                None   \n",
       "1            None                None   \n",
       "2            None                None   \n",
       "3            None                None   \n",
       "4            None                None   \n",
       "\n",
       "                               Residency Requirement Posting Date Post Until  \\\n",
       "0                                               None         None       None   \n",
       "1  New York City residency is generally required ...   2012-01-26       None   \n",
       "2                                               None         None       None   \n",
       "3                                               None         None       None   \n",
       "4                NYCHA has no residency requirement.   2014-01-09       None   \n",
       "\n",
       "  Posting Updated Process Date  \n",
       "0            None         None  \n",
       "1      2012-01-26   2019-12-17  \n",
       "2            None         None  \n",
       "3            None         None  \n",
       "4      2014-01-08   2019-12-17  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_types.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### many rows with Null rows\n",
    "\n",
    "This has been caused because I was trying to cast the Posting Date as a date and in over 1000 records, this fails\n",
    "> \n",
    "    root\n",
    "     |-- Agency: string (nullable = true)\n",
    "     |-- Job Category: string (nullable = true)\n",
    "     |-- Salary Range From: integer (nullable = true)\n",
    "     |-- Salary Range To: integer (nullable = true)\n",
    "     |-- Salary Frequency: string (nullable = true)\n",
    "     |-- Minimum Qual Requirements: string (nullable = true)\n",
    "     |-- Posting Date: date (nullable = true) <<<<<<<<<<<<<<<<<<<<<<<<,  \n",
    "\n",
    " There are over 1000 records, where I thnk the failure to case to date is resulting in nulls.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------------+--------------+--------------+-------------------+-------------+-----+------------+-----------------------------+-----------------+---------------+----------------+-------------+------------------+---------------+-------------------------+----------------+----------------------+--------+-----------+---------------+-------------------+---------------------+------------+----------+---------------+------------+\n",
      "|Job ID|Agency|Posting Type|# Of Positions|Business Title|Civil Service Title|Title Code No|Level|Job Category|Full-Time/Part-Time indicator|Salary Range From|Salary Range To|Salary Frequency|Work Location|Division/Work Unit|Job Description|Minimum Qual Requirements|Preferred Skills|Additional Information|To Apply|Hours/Shift|Work Location 1|Recruitment Contact|Residency Requirement|Posting Date|Post Until|Posting Updated|Process Date|\n",
      "+------+------+------------+--------------+--------------+-------------------+-------------+-----+------------+-----------------------------+-----------------+---------------+----------------+-------------+------------------+---------------+-------------------------+----------------+----------------------+--------+-----------+---------------+-------------------+---------------------+------------+----------+---------------+------------+\n",
      "|  null|  null|        null|          null|          null|               null|         null| null|        null|                         null|             null|           null|            null|         null|              null|           null|                     null|            null|                  null|    null|       null|           null|               null|                 null|        null|      null|           null|        null|\n",
      "|  null|  null|        null|          null|          null|               null|         null| null|        null|                         null|             null|           null|            null|         null|              null|           null|                     null|            null|                  null|    null|       null|           null|               null|                 null|        null|      null|           null|        null|\n",
      "|  null|  null|        null|          null|          null|               null|         null| null|        null|                         null|             null|           null|            null|         null|              null|           null|                     null|            null|                  null|    null|       null|           null|               null|                 null|        null|      null|           null|        null|\n",
      "|  null|  null|        null|          null|          null|               null|         null| null|        null|                         null|             null|           null|            null|         null|              null|           null|                     null|            null|                  null|    null|       null|           null|               null|                 null|        null|      null|           null|        null|\n",
      "|  null|  null|        null|          null|          null|               null|         null| null|        null|                         null|             null|           null|            null|         null|              null|           null|                     null|            null|                  null|    null|       null|           null|               null|                 null|        null|      null|           null|        null|\n",
      "|  null|  null|        null|          null|          null|               null|         null| null|        null|                         null|             null|           null|            null|         null|              null|           null|                     null|            null|                  null|    null|       null|           null|               null|                 null|        null|      null|           null|        null|\n",
      "|  null|  null|        null|          null|          null|               null|         null| null|        null|                         null|             null|           null|            null|         null|              null|           null|                     null|            null|                  null|    null|       null|           null|               null|                 null|        null|      null|           null|        null|\n",
      "|  null|  null|        null|          null|          null|               null|         null| null|        null|                         null|             null|           null|            null|         null|              null|           null|                     null|            null|                  null|    null|       null|           null|               null|                 null|        null|      null|           null|        null|\n",
      "|  null|  null|        null|          null|          null|               null|         null| null|        null|                         null|             null|           null|            null|         null|              null|           null|                     null|            null|                  null|    null|       null|           null|               null|                 null|        null|      null|           null|        null|\n",
      "|  null|  null|        null|          null|          null|               null|         null| null|        null|                         null|             null|           null|            null|         null|              null|           null|                     null|            null|                  null|    null|       null|           null|               null|                 null|        null|      null|           null|        null|\n",
      "|  null|  null|        null|          null|          null|               null|         null| null|        null|                         null|             null|           null|            null|         null|              null|           null|                     null|            null|                  null|    null|       null|           null|               null|                 null|        null|      null|           null|        null|\n",
      "|  null|  null|        null|          null|          null|               null|         null| null|        null|                         null|             null|           null|            null|         null|              null|           null|                     null|            null|                  null|    null|       null|           null|               null|                 null|        null|      null|           null|        null|\n",
      "|  null|  null|        null|          null|          null|               null|         null| null|        null|                         null|             null|           null|            null|         null|              null|           null|                     null|            null|                  null|    null|       null|           null|               null|                 null|        null|      null|           null|        null|\n",
      "|  null|  null|        null|          null|          null|               null|         null| null|        null|                         null|             null|           null|            null|         null|              null|           null|                     null|            null|                  null|    null|       null|           null|               null|                 null|        null|      null|           null|        null|\n",
      "|  null|  null|        null|          null|          null|               null|         null| null|        null|                         null|             null|           null|            null|         null|              null|           null|                     null|            null|                  null|    null|       null|           null|               null|                 null|        null|      null|           null|        null|\n",
      "|  null|  null|        null|          null|          null|               null|         null| null|        null|                         null|             null|           null|            null|         null|              null|           null|                     null|            null|                  null|    null|       null|           null|               null|                 null|        null|      null|           null|        null|\n",
      "|  null|  null|        null|          null|          null|               null|         null| null|        null|                         null|             null|           null|            null|         null|              null|           null|                     null|            null|                  null|    null|       null|           null|               null|                 null|        null|      null|           null|        null|\n",
      "|  null|  null|        null|          null|          null|               null|         null| null|        null|                         null|             null|           null|            null|         null|              null|           null|                     null|            null|                  null|    null|       null|           null|               null|                 null|        null|      null|           null|        null|\n",
      "|  null|  null|        null|          null|          null|               null|         null| null|        null|                         null|             null|           null|            null|         null|              null|           null|                     null|            null|                  null|    null|       null|           null|               null|                 null|        null|      null|           null|        null|\n",
      "|  null|  null|        null|          null|          null|               null|         null| null|        null|                         null|             null|           null|            null|         null|              null|           null|                     null|            null|                  null|    null|       null|           null|               null|                 null|        null|      null|           null|        null|\n",
      "+------+------+------------+--------------+--------------+-------------------+-------------+-----+------------+-----------------------------+-----------------+---------------+----------------+-------------+------------------+---------------+-------------------------+----------------+----------------------+--------+-----------+---------------+-------------------+---------------------+------------+----------+---------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_types.where(F.col('Job ID').isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|Posting Date|\n",
      "+------------+\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "|        null|\n",
      "+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_types.select('Posting Date').where(F.col('Job ID').isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "featues = [\"Agency\", \n",
    "           \"Job Category\",\n",
    "           \"Salary Range From\",\n",
    "           \"Salary Range To\",\n",
    "           \"Salary Frequency\",\n",
    "           \"Minimum Qual Requirements\",\n",
    "           \"Posting Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_required_feaures = df_with_types.select(featues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Agency: string (nullable = true)\n",
      " |-- Job Category: string (nullable = true)\n",
      " |-- Salary Range From: integer (nullable = true)\n",
      " |-- Salary Range To: integer (nullable = true)\n",
      " |-- Salary Frequency: string (nullable = true)\n",
      " |-- Minimum Qual Requirements: string (nullable = true)\n",
      " |-- Posting Date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_required_feaures.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agency</th>\n",
       "      <th>Job Category</th>\n",
       "      <th>Salary Range From</th>\n",
       "      <th>Salary Range To</th>\n",
       "      <th>Salary Frequency</th>\n",
       "      <th>Minimum Qual Requirements</th>\n",
       "      <th>Posting Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEPARTMENT OF BUSINESS SERV.</td>\n",
       "      <td>None</td>\n",
       "      <td>60740.0</td>\n",
       "      <td>162014.0</td>\n",
       "      <td>Annual</td>\n",
       "      <td>\"1. A baccalaureate degree from an accredited ...</td>\n",
       "      <td>2012-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NYC HOUSING AUTHORITY</td>\n",
       "      <td>Maintenance &amp; Operations</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>1. Five years of full-time satisfactory experi...</td>\n",
       "      <td>2014-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NYC HOUSING AUTHORITY</td>\n",
       "      <td>Maintenance &amp; Operations</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>1. Five years of full-time satisfactory experi...</td>\n",
       "      <td>2014-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DEPT OF ENVIRONMENT PROTECTION</td>\n",
       "      <td>Health Public Safety, Inspections, &amp; Enforcement</td>\n",
       "      <td>50623.0</td>\n",
       "      <td>75083.0</td>\n",
       "      <td>Annual</td>\n",
       "      <td>Qualification Requirements  A baccalaureate de...</td>\n",
       "      <td>2013-12-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NYC HOUSING AUTHORITY</td>\n",
       "      <td>Engineering, Architecture, &amp; Planning</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>Annual</td>\n",
       "      <td>\"1. A master's degree from an accredited colle...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LAW DEPARTMENT</td>\n",
       "      <td>Clerical &amp; Administrative Support</td>\n",
       "      <td>30683.0</td>\n",
       "      <td>49707.0</td>\n",
       "      <td>Annual</td>\n",
       "      <td>Qualification Requirements  A four-year high s...</td>\n",
       "      <td>2014-06-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Agency  \\\n",
       "0                            None   \n",
       "1    DEPARTMENT OF BUSINESS SERV.   \n",
       "2                            None   \n",
       "3                            None   \n",
       "4           NYC HOUSING AUTHORITY   \n",
       "5           NYC HOUSING AUTHORITY   \n",
       "6                            None   \n",
       "7  DEPT OF ENVIRONMENT PROTECTION   \n",
       "8           NYC HOUSING AUTHORITY   \n",
       "9                  LAW DEPARTMENT   \n",
       "\n",
       "                                       Job Category  Salary Range From  \\\n",
       "0                                              None                NaN   \n",
       "1                                              None            60740.0   \n",
       "2                                              None                NaN   \n",
       "3                                              None                NaN   \n",
       "4                          Maintenance & Operations               35.0   \n",
       "5                          Maintenance & Operations               35.0   \n",
       "6                                              None                NaN   \n",
       "7  Health Public Safety, Inspections, & Enforcement            50623.0   \n",
       "8             Engineering, Architecture, & Planning            90000.0   \n",
       "9                 Clerical & Administrative Support            30683.0   \n",
       "\n",
       "   Salary Range To Salary Frequency  \\\n",
       "0              NaN             None   \n",
       "1         162014.0           Annual   \n",
       "2              NaN             None   \n",
       "3              NaN             None   \n",
       "4             35.0           Hourly   \n",
       "5             35.0           Hourly   \n",
       "6              NaN             None   \n",
       "7          75083.0           Annual   \n",
       "8         110000.0           Annual   \n",
       "9          49707.0           Annual   \n",
       "\n",
       "                           Minimum Qual Requirements Posting Date  \n",
       "0                                               None         None  \n",
       "1  \"1. A baccalaureate degree from an accredited ...   2012-01-26  \n",
       "2                                               None         None  \n",
       "3                                               None         None  \n",
       "4  1. Five years of full-time satisfactory experi...   2014-01-09  \n",
       "5  1. Five years of full-time satisfactory experi...   2014-01-09  \n",
       "6                                               None         None  \n",
       "7  Qualification Requirements  A baccalaureate de...   2013-12-20  \n",
       "8  \"1. A master's degree from an accredited colle...         None  \n",
       "9  Qualification Requirements  A four-year high s...   2014-06-26  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_required_feaures.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "myc_jobs_schema2 = StructType(fields=[StructField(\"Job ID\", StringType(), True),\n",
    "                                    StructField(\"Agency\", StringType(), True),\n",
    "                                    StructField(\"Posting Type\", StringType(), True),\n",
    "                                    StructField(\"# Of Positions\", StringType(), True),\n",
    "                                    StructField(\"Business Title\", StringType(), True),\n",
    "                                    StructField(\"Civil Service Title\", StringType(), True),\n",
    "                                    StructField(\"Title Code No\", StringType(), True),\n",
    "                                    StructField(\"Level\", StringType(), True),\n",
    "                                    StructField(\"Job Category\", StringType(), True),\n",
    "                                    StructField(\"Full-Time/Part-Time indicator\", StringType(), True),\n",
    "                                    StructField(\"Salary Range From\", FloatType(), True),\n",
    "                                    StructField(\"Salary Range To\", FloatType(), True),\n",
    "                                    StructField(\"Salary Frequency\", StringType(), True),\n",
    "                                    StructField(\"Work Location\", StringType(), True),\n",
    "                                    StructField(\"Division/Work Unit\", StringType(), True),\n",
    "                                    StructField(\"Job Description\", StringType(), True),\n",
    "                                    StructField(\"Minimum Qual Requirements\", StringType(), True),\n",
    "                                    StructField(\"Preferred Skills\", StringType(), True),\n",
    "                                    StructField(\"Additional Information\", StringType(), True),\n",
    "                                    StructField(\"To Apply\", StringType(), True),\n",
    "                                    StructField(\"Hours/Shift\", StringType(), True),\n",
    "                                    StructField(\"Work Location 1\", StringType(), True),\n",
    "                                    StructField(\"Recruitment Contact\", StringType(), True),\n",
    "                                    StructField(\"Residency Requirement\", StringType(), True),\n",
    "                                    StructField(\"Posting Date\", StringType(), True),\n",
    "                                    StructField(\"Post Until\", StringType(), True),\n",
    "                                    StructField(\"Posting Updated\", StringType(), True),\n",
    "                                    StructField(\"Process Date\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_types2 = spark.read.schema(myc_jobs_schema).csv(\"/dataset/nyc-jobs.csv\", header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Job ID: string (nullable = true)\n",
      " |-- Agency: string (nullable = true)\n",
      " |-- Posting Type: string (nullable = true)\n",
      " |-- # Of Positions: string (nullable = true)\n",
      " |-- Business Title: string (nullable = true)\n",
      " |-- Civil Service Title: string (nullable = true)\n",
      " |-- Title Code No: string (nullable = true)\n",
      " |-- Level: string (nullable = true)\n",
      " |-- Job Category: string (nullable = true)\n",
      " |-- Full-Time/Part-Time indicator: string (nullable = true)\n",
      " |-- Salary Range From: float (nullable = true)\n",
      " |-- Salary Range To: float (nullable = true)\n",
      " |-- Salary Frequency: string (nullable = true)\n",
      " |-- Work Location: string (nullable = true)\n",
      " |-- Division/Work Unit: string (nullable = true)\n",
      " |-- Job Description: string (nullable = true)\n",
      " |-- Minimum Qual Requirements: string (nullable = true)\n",
      " |-- Preferred Skills: string (nullable = true)\n",
      " |-- Additional Information: string (nullable = true)\n",
      " |-- To Apply: string (nullable = true)\n",
      " |-- Hours/Shift: string (nullable = true)\n",
      " |-- Work Location 1: string (nullable = true)\n",
      " |-- Recruitment Contact: string (nullable = true)\n",
      " |-- Residency Requirement: string (nullable = true)\n",
      " |-- Posting Date: date (nullable = true)\n",
      " |-- Post Until: string (nullable = true)\n",
      " |-- Posting Updated: date (nullable = true)\n",
      " |-- Process Date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_types2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job ID</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Posting Type</th>\n",
       "      <th># Of Positions</th>\n",
       "      <th>Business Title</th>\n",
       "      <th>Civil Service Title</th>\n",
       "      <th>Title Code No</th>\n",
       "      <th>Level</th>\n",
       "      <th>Job Category</th>\n",
       "      <th>Full-Time/Part-Time indicator</th>\n",
       "      <th>...</th>\n",
       "      <th>Additional Information</th>\n",
       "      <th>To Apply</th>\n",
       "      <th>Hours/Shift</th>\n",
       "      <th>Work Location 1</th>\n",
       "      <th>Recruitment Contact</th>\n",
       "      <th>Residency Requirement</th>\n",
       "      <th>Posting Date</th>\n",
       "      <th>Post Until</th>\n",
       "      <th>Posting Updated</th>\n",
       "      <th>Process Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1322 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Job ID Agency Posting Type # Of Positions Business Title  \\\n",
       "0      None   None         None           None           None   \n",
       "1      None   None         None           None           None   \n",
       "2      None   None         None           None           None   \n",
       "3      None   None         None           None           None   \n",
       "4      None   None         None           None           None   \n",
       "...     ...    ...          ...            ...            ...   \n",
       "1317   None   None         None           None           None   \n",
       "1318   None   None         None           None           None   \n",
       "1319   None   None         None           None           None   \n",
       "1320   None   None         None           None           None   \n",
       "1321   None   None         None           None           None   \n",
       "\n",
       "     Civil Service Title Title Code No Level Job Category  \\\n",
       "0                   None          None  None         None   \n",
       "1                   None          None  None         None   \n",
       "2                   None          None  None         None   \n",
       "3                   None          None  None         None   \n",
       "4                   None          None  None         None   \n",
       "...                  ...           ...   ...          ...   \n",
       "1317                None          None  None         None   \n",
       "1318                None          None  None         None   \n",
       "1319                None          None  None         None   \n",
       "1320                None          None  None         None   \n",
       "1321                None          None  None         None   \n",
       "\n",
       "     Full-Time/Part-Time indicator  ...  Additional Information  To Apply  \\\n",
       "0                             None  ...                    None      None   \n",
       "1                             None  ...                    None      None   \n",
       "2                             None  ...                    None      None   \n",
       "3                             None  ...                    None      None   \n",
       "4                             None  ...                    None      None   \n",
       "...                            ...  ...                     ...       ...   \n",
       "1317                          None  ...                    None      None   \n",
       "1318                          None  ...                    None      None   \n",
       "1319                          None  ...                    None      None   \n",
       "1320                          None  ...                    None      None   \n",
       "1321                          None  ...                    None      None   \n",
       "\n",
       "     Hours/Shift Work Location 1 Recruitment Contact Residency Requirement  \\\n",
       "0           None            None                None                  None   \n",
       "1           None            None                None                  None   \n",
       "2           None            None                None                  None   \n",
       "3           None            None                None                  None   \n",
       "4           None            None                None                  None   \n",
       "...          ...             ...                 ...                   ...   \n",
       "1317        None            None                None                  None   \n",
       "1318        None            None                None                  None   \n",
       "1319        None            None                None                  None   \n",
       "1320        None            None                None                  None   \n",
       "1321        None            None                None                  None   \n",
       "\n",
       "     Posting Date Post Until Posting Updated Process Date  \n",
       "0            None       None            None         None  \n",
       "1            None       None            None         None  \n",
       "2            None       None            None         None  \n",
       "3            None       None            None         None  \n",
       "4            None       None            None         None  \n",
       "...           ...        ...             ...          ...  \n",
       "1317         None       None            None         None  \n",
       "1318         None       None            None         None  \n",
       "1319         None       None            None         None  \n",
       "1320         None       None            None         None  \n",
       "1321         None       None            None         None  \n",
       "\n",
       "[1322 rows x 28 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_types2.select(\"*\").where(F.col('Job ID').isNull()).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "still loads of Nulls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_types2.select('Agency').where(F.col('Job ID').isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "     \n",
    "df_with_types2.where(F.col('Job ID').isNull() | F.isnan(F.col('Job ID'))).count()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------+\n",
      "|count(CASE WHEN ((Job ID IS NULL) OR isnan(Job ID)) THEN Job ID END)|\n",
      "+--------------------------------------------------------------------+\n",
      "|                                                                   0|\n",
      "+--------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_types2.select(F.count( F.when(F.col('Job ID').isNull() | F.isnan(F.col('Job ID')),F.col('Job ID') )  ) ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot\n",
    "\n",
    "I obviously am not fully understanding what is going wrong with the schema.  So I'll admit there's a area I need to brush up on / seek advice.   \n",
    "\n",
    "So to allow me to continue the assessment, I use inferSchema and convert any columns that are not the type I need when I need to, plus some engineering to create the required columns.  Alos, I reduce the df as soon as possible, to only the features that are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/dataset/nyc-jobs.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Agency\", \n",
    "           \"Job Category\",\n",
    "           \"Salary Range From\",\n",
    "           \"Salary Range To\",\n",
    "           \"Salary Frequency\",\n",
    "           \"Minimum Qual Requirements\",\n",
    "           \"Posting Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.select(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Agency: string (nullable = true)\n",
      " |-- Job Category: string (nullable = true)\n",
      " |-- Salary Range From: double (nullable = true)\n",
      " |-- Salary Range To: double (nullable = true)\n",
      " |-- Salary Frequency: string (nullable = true)\n",
      " |-- Minimum Qual Requirements: string (nullable = true)\n",
      " |-- Posting Date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "- Salary \n",
    "\n",
    "    - Required: a function to derive a salary based on \"Salary Range From\", \"Salary Range To\" and \"Salary Frequency\"\n",
    "        The resultant salary must be in the same units across each \"Salary Frequency\" so that a comparison can be made\n",
    "\n",
    "\n",
    "- Minimum Qual Requirements \n",
    "\n",
    "    - Required: a function to extrapolate any qualification specification.  I may end up having a simply flag:  required_degree: boolean\n",
    "   \n",
    "   \n",
    "- Posting Date - only about half of the records have a valid data in this field\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required: derive a salary based on \"Salary Range From\", \"Salary Range To\" and \"Salary Frequency\" The resultant salary must be in the same units across each \"Salary Frequency\" so that a comparison can be made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,expr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when \"Salary Range From\" is not null and not 0, then calculate the midrange salary, i.e. sal = (min + (max - min)/2)\n",
    " otherwise use \"Salary Range To\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.filter(col(\"Salary Range From\").cast('int') == 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2930"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.filter(~col(\"Salary Range From\").isNull()).filter(col(\"Salary Range From\") > 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2946"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had to rename the columns and remove the spaces otherwise the expr saw the \n",
    "column as a string.\n",
    "\n",
    "So this didn't work:\n",
    "\n",
    "`\n",
    "    df2 = df.withColumn(\"Hourly Salary mixed freq\",\n",
    "                    expr(\"\"\"\n",
    "                        case                              \n",
    "                             when \n",
    "                                'Salary Range From' is null\n",
    "                             then 'Salary Range To'\n",
    "                             when \n",
    "                                 'Salary Range From' == 0\n",
    "                             then 'Salary Range To'\n",
    "                             else\n",
    "                                 'Salary Range From' + ('Salary Range To' - 'Salary Range From')/2\n",
    "                        end\n",
    "                    \"\"\"\n",
    "                    ))\n",
    "`                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame,Column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.withColumnRenamed('Salary Range From','SalaryRangeFrom'). \\\n",
    "         withColumnRenamed('Salary Range To','SalaryRangeTo'). \\\n",
    "         withColumn(\"SalaryMixedFreq\",\n",
    "                    expr(\"\"\"\n",
    "                        case                              \n",
    "                             when \n",
    "                                SalaryRangeFrom is null\n",
    "                             then SalaryRangeTo\n",
    "                             when \n",
    "                                 SalaryRangeFrom == 0\n",
    "                             then SalaryRangeTo\n",
    "                             else\n",
    "                                 SalaryRangeFrom + (SalaryRangeTo - SalaryRangeFrom)/2\n",
    "                        end\n",
    "                    \"\"\"\n",
    "                    )). \\\n",
    "         withColumnRenamed(\"Salary Frequency\",\"SalaryFrequency\"). \\\n",
    "         withColumn(\"HourlySalary\",\n",
    "                    expr(\"\"\"\n",
    "                        case\n",
    "                            when \n",
    "                                SalaryFrequency == \"Hourly\"\n",
    "                            then SalaryMixedFreq\n",
    "                            when\n",
    "                                SalaryFrequency == \"Daily\"\n",
    "                            then\n",
    "                                round(SalaryMixedFreq / 8,2)\n",
    "                            else\n",
    "                                round(SalaryMixedFreq / 1757,2)\n",
    "                        end\n",
    "                   \"\"\"\n",
    "                   ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalaryRangeFrom</th>\n",
       "      <th>SalaryRangeTo</th>\n",
       "      <th>SalaryMixedFreq</th>\n",
       "      <th>HourlySalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42405.00</td>\n",
       "      <td>65485.00</td>\n",
       "      <td>53945.0</td>\n",
       "      <td>30.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60740.00</td>\n",
       "      <td>162014.00</td>\n",
       "      <td>111377.0</td>\n",
       "      <td>63.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51907.68</td>\n",
       "      <td>54580.32</td>\n",
       "      <td>53244.0</td>\n",
       "      <td>30.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51907.68</td>\n",
       "      <td>54580.32</td>\n",
       "      <td>53244.0</td>\n",
       "      <td>30.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50598.00</td>\n",
       "      <td>85053.00</td>\n",
       "      <td>67825.5</td>\n",
       "      <td>38.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50623.00</td>\n",
       "      <td>75083.00</td>\n",
       "      <td>62853.0</td>\n",
       "      <td>35.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90000.00</td>\n",
       "      <td>110000.00</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>56.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30683.00</td>\n",
       "      <td>49707.00</td>\n",
       "      <td>40195.0</td>\n",
       "      <td>22.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalaryRangeFrom  SalaryRangeTo  SalaryMixedFreq  HourlySalary\n",
       "0         42405.00       65485.00          53945.0         30.70\n",
       "1         60740.00      162014.00         111377.0         63.39\n",
       "2         51907.68       54580.32          53244.0         30.30\n",
       "3         51907.68       54580.32          53244.0         30.30\n",
       "4            35.00          35.00             35.0         35.00\n",
       "5            35.00          35.00             35.0         35.00\n",
       "6         50598.00       85053.00          67825.5         38.60\n",
       "7         50623.00       75083.00          62853.0         35.77\n",
       "8         90000.00      110000.00         100000.0         56.92\n",
       "9         30683.00       49707.00          40195.0         22.88"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.select([\"SalaryRangeFrom\",\"SalaryRangeTo\",\"SalaryMixedFreq\",\"HourlySalary\"]).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test above case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField,DoubleType,StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.5\n"
     ]
    }
   ],
   "source": [
    "print(f\"{700 / 8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probably better to seratate test data with source data, but for\n",
    "# simplicity I'll save the csv in teh same location:\n",
    "\n",
    "import sys\n",
    "with open(\"/dataset/test_salary_data.csv\",\"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "SalaryRangeFrom,SalaryRangeTo,SalaryFrequency,ExpectedSalaryMixedFreq,ExpectedHourlySalary\n",
    ",10,\"Hourly\",10,10\n",
    "0,10,\"Hourly\",10,10\n",
    "5,10,\"Hourly\",7.5,7.5\n",
    ",800,\"Daily\",800,10\n",
    "0,800,\"Daily\",800,10\n",
    "600,800,\"Daily\",700,87.5\n",
    "0,100000,\"Annual\",100000,56.92\n",
    ",100000,\"Annual\",100000,56.92\n",
    "80000,100000,\"Annual\",90000,51.22\n",
    "\"\"\")\n",
    "            \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = spark.read.csv(\"/dataset/test_salary_data.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+---------------+-----------------------+--------------------+\n",
      "|SalaryRangeFrom|SalaryRangeTo|SalaryFrequency|ExpectedSalaryMixedFreq|ExpectedHourlySalary|\n",
      "+---------------+-------------+---------------+-----------------------+--------------------+\n",
      "|           null|           10|         Hourly|                     10|                  10|\n",
      "|              0|           10|         Hourly|                     10|                  10|\n",
      "|              5|           10|         Hourly|                    7.5|                 7.5|\n",
      "|           null|          800|          Daily|                    800|                  10|\n",
      "|              0|          800|          Daily|                    800|                  10|\n",
      "|            600|          800|          Daily|                    700|                87.5|\n",
      "|              0|       100000|         Annual|                 100000|               56.92|\n",
      "|           null|       100000|         Annual|                 100000|               56.92|\n",
      "|          80000|       100000|         Annual|                  90000|               51.22|\n",
      "+---------------+-------------+---------------+-----------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df2 = test_df.withColumn(\"SalaryMixedFreq\",\n",
    "                    expr(\"\"\"\n",
    "                        case                              \n",
    "                             when \n",
    "                                SalaryRangeFrom is null\n",
    "                             then SalaryRangeTo\n",
    "                             when \n",
    "                                 SalaryRangeFrom == 0\n",
    "                             then SalaryRangeTo\n",
    "                             else\n",
    "                                 SalaryRangeFrom + (SalaryRangeTo - SalaryRangeFrom)/2\n",
    "                        end\n",
    "                    \"\"\"\n",
    "                    )). \\\n",
    "         withColumn(\"HourlySalary\",\n",
    "                    expr(\"\"\"\n",
    "                        case\n",
    "                            when \n",
    "                                SalaryFrequency == \"Hourly\"\n",
    "                            then SalaryMixedFreq\n",
    "                            when\n",
    "                                SalaryFrequency == \"Daily\"\n",
    "                            then\n",
    "                                round(SalaryMixedFreq / 8,2)\n",
    "                            else\n",
    "                                round(SalaryMixedFreq / 1757,2)\n",
    "                        end\n",
    "                   \"\"\"\n",
    "                   ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+---------------+-----------------------+--------------------+---------------+------------+\n",
      "|SalaryRangeFrom|SalaryRangeTo|SalaryFrequency|ExpectedSalaryMixedFreq|ExpectedHourlySalary|SalaryMixedFreq|HourlySalary|\n",
      "+---------------+-------------+---------------+-----------------------+--------------------+---------------+------------+\n",
      "|           null|           10|         Hourly|                     10|                  10|             10|          10|\n",
      "|              0|           10|         Hourly|                     10|                  10|             10|          10|\n",
      "|              5|           10|         Hourly|                    7.5|                 7.5|            7.5|         7.5|\n",
      "|           null|          800|          Daily|                    800|                  10|            800|       100.0|\n",
      "|              0|          800|          Daily|                    800|                  10|            800|       100.0|\n",
      "|            600|          800|          Daily|                    700|                87.5|          700.0|        87.5|\n",
      "|              0|       100000|         Annual|                 100000|               56.92|         100000|       56.92|\n",
      "|           null|       100000|         Annual|                 100000|               56.92|         100000|       56.92|\n",
      "|          80000|       100000|         Annual|                  90000|               51.22|        90000.0|       51.22|\n",
      "+---------------+-------------+---------------+-----------------------+--------------------+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalaryRangeFrom</th>\n",
       "      <th>SalaryRangeTo</th>\n",
       "      <th>SalaryFrequency</th>\n",
       "      <th>ExpectedSalaryMixedFreq</th>\n",
       "      <th>ExpectedHourlySalary</th>\n",
       "      <th>SalaryMixedFreq</th>\n",
       "      <th>HourlySalary</th>\n",
       "      <th>Test1</th>\n",
       "      <th>Test2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>Hourly</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>800</td>\n",
       "      <td>Daily</td>\n",
       "      <td>800</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>100.0</td>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>Daily</td>\n",
       "      <td>800</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>100.0</td>\n",
       "      <td>PASS</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600</td>\n",
       "      <td>800</td>\n",
       "      <td>Daily</td>\n",
       "      <td>700</td>\n",
       "      <td>87.5</td>\n",
       "      <td>700.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>Annual</td>\n",
       "      <td>100000</td>\n",
       "      <td>56.92</td>\n",
       "      <td>100000</td>\n",
       "      <td>56.92</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>100000</td>\n",
       "      <td>Annual</td>\n",
       "      <td>100000</td>\n",
       "      <td>56.92</td>\n",
       "      <td>100000</td>\n",
       "      <td>56.92</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>80000</td>\n",
       "      <td>100000</td>\n",
       "      <td>Annual</td>\n",
       "      <td>90000</td>\n",
       "      <td>51.22</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>51.22</td>\n",
       "      <td>PASS</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SalaryRangeFrom SalaryRangeTo SalaryFrequency ExpectedSalaryMixedFreq  \\\n",
       "0            None            10          Hourly                      10   \n",
       "1               0            10          Hourly                      10   \n",
       "2               5            10          Hourly                     7.5   \n",
       "3            None           800           Daily                     800   \n",
       "4               0           800           Daily                     800   \n",
       "5             600           800           Daily                     700   \n",
       "6               0        100000          Annual                  100000   \n",
       "7            None        100000          Annual                  100000   \n",
       "8           80000        100000          Annual                   90000   \n",
       "\n",
       "  ExpectedHourlySalary SalaryMixedFreq HourlySalary Test1 Test2  \n",
       "0                   10              10           10  PASS  PASS  \n",
       "1                   10              10           10  PASS  PASS  \n",
       "2                  7.5             7.5          7.5  PASS  PASS  \n",
       "3                   10             800        100.0  PASS  FAIL  \n",
       "4                   10             800        100.0  PASS  FAIL  \n",
       "5                 87.5           700.0         87.5  PASS  PASS  \n",
       "6                56.92          100000        56.92  PASS  PASS  \n",
       "7                56.92          100000        56.92  PASS  PASS  \n",
       "8                51.22         90000.0        51.22  PASS  PASS  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df2.withColumn(\"Test1\",expr(\"\"\"\n",
    "                              case\n",
    "                                  when (ExpectedSalaryMixedFreq * 1.0) == (SalaryMixedFreq * 1.0) then \"PASS\"\n",
    "                              else \n",
    "                                  \"FAIL\"\n",
    "                              end\n",
    "                              \"\"\")).\\\n",
    "        withColumn(\"Test2\",expr(\"\"\"\n",
    "                            case\n",
    "                                when (ExpectedHourlySalary * 1.0) == (HourlySalary * 1.0) then \"PASS\"\n",
    "                            else\n",
    "                                \"FAIL\"\n",
    "                            end\n",
    "                            \"\"\")).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app  boot     dev  home  lib64\tmnt\t  opt\troot  sbin  sys  usr\tvar\r\n",
      "bin  dataset  etc  lib\t media\tnotebook  proc\trun   srv   tmp  utils\r\n"
     ]
    }
   ],
   "source": [
    "!ls .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; \n",
    "sys.path.insert(0, '..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import udf_functions as UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function get_SalaryMixedFreq in module utils.udf_functions:\n",
      "\n",
      "get_SalaryMixedFreq(df: pyspark.sql.dataframe.DataFrame) -> float\n",
      "    Description:\n",
      "    \n",
      "    Create SalaryMixedFreq Column as follows:\n",
      "        When \"Salary Range From\" is not null and not 0, then calculate the midrange salary, i.e. sal = (min + (max - min)/2)\n",
      "        else use \"Salary Range To\" as the salary\n",
      "    \n",
      "    :param df: input dataframe\n",
      "    :return: SalaryMixedFreq\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(UDF.get_SalaryMixedFreq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING by copying the function in line here to remove utils from the error msgm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def get_SalaryMixedFreq(SalaryRangeFrom, SalaryRangeTo) -> float:\n",
    "    \"\"\"\n",
    "        Description:\n",
    "    \n",
    "        Create SalaryMixedFreq Column as follows:\n",
    "            When \"Salary Range From\" is not null and not 0, then calculate the midrange salary, i.e. sal = (min + (max - min)/2)\n",
    "            else use \"Salary Range To\" as the salary\n",
    "\n",
    "        :param SalaryRangeFrom:\n",
    "        :param SalaryRangeTo:\n",
    "        :return: SalaryMixedFreq\n",
    "\n",
    "    \"\"\"\n",
    "    return_df = df.withColumn(\"SalaryMixedFreq\",\n",
    "                                expr(\"\"\"\n",
    "                                    case                              \n",
    "                                        when \n",
    "                                            SalaryRangeFrom is null\n",
    "                                        then SalaryRangeTo\n",
    "                                        when \n",
    "                                            SalaryRangeFrom == 0\n",
    "                                        then SalaryRangeTo\n",
    "                                        else\n",
    "                                            SalaryRangeFrom + (SalaryRangeTo - SalaryRangeFrom)/2\n",
    "                                    end\n",
    "                                \"\"\"\n",
    "                                ))\n",
    "    return return_df(\"SalaryMixedFreq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_SalaryMixedFreq_udf=udf(get_SalaryMixedFreq,FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/pyspark/serializers.py\", line 597, in dumps\n",
      "    return cloudpickle.dumps(obj, 2)\n",
      "  File \"/opt/spark/python/pyspark/cloudpickle.py\", line 863, in dumps\n",
      "    cp.dump(obj)\n",
      "  File \"/opt/spark/python/pyspark/cloudpickle.py\", line 260, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "  File \"/usr/lib/python3.7/pickle.py\", line 437, in dump\n",
      "    self.save(obj)\n",
      "  File \"/usr/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/lib/python3.7/pickle.py\", line 771, in save_tuple\n",
      "    save(element)\n",
      "  File \"/usr/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/opt/spark/python/pyspark/cloudpickle.py\", line 400, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/opt/spark/python/pyspark/cloudpickle.py\", line 549, in save_function_tuple\n",
      "    save(state)\n",
      "  File \"/usr/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/usr/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/usr/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/usr/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/usr/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/usr/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/usr/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/lib/python3.7/pickle.py\", line 856, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/usr/lib/python3.7/pickle.py\", line 882, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/usr/lib/python3.7/pickle.py\", line 524, in save\n",
      "    rv = reduce(self.proto)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/opt/spark/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 332, in get_return_value\n",
      "    format(target_id, \".\", name, value))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o32.__getstate__. Trace:\n",
      "py4j.Py4JException: Method __getstate__([]) does not exist\n",
      "\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n",
      "\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:274)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not serialize object: Py4JError: An error occurred while calling o32.__getstate__. Trace:\npy4j.Py4JException: Method __getstate__([]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:274)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/spark/python/pyspark/serializers.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickleError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, protocol)\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCloudPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_tuple\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m             \u001b[0;31m# Subtle.  Same as in the big comment below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    399\u001b[0m                 or themodule is None):\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_function_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function_tuple\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'qualname'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTUPLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    881\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    881\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    881\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m                 \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                     format(target_id, \".\", name, value))\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o32.__getstate__. Trace:\npy4j.Py4JException: Method __getstate__([]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:274)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-01ad01c4f1d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                      get_SalaryMixedFreq_udf(\n\u001b[1;32m      3\u001b[0m                          \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Salary Range From'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                          \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Salary Range To'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                      ))\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/udf.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massigned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0massignments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/udf.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mjudf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_judf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_to_java_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/udf.py\u001b[0m in \u001b[0;36m_judf\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;31m# and should have a minimal performance impact.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_judf_placeholder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_judf_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_judf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_judf_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/udf.py\u001b[0m in \u001b[0;36m_create_judf\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mwrapped_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrap_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturnType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mjdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseDataType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturnType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         judf = sc._jvm.org.apache.spark.sql.execution.python.UserDefinedPythonFunction(\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/udf.py\u001b[0m in \u001b[0;36m_wrap_function\u001b[0;34m(sc, func, returnType)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrap_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturnType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturnType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mpickled_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincludes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_for_python_RDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n\u001b[1;32m     37\u001b[0m                                   sc.pythonVer, broadcast_vars, sc._javaAccumulator)\n",
      "\u001b[0;32m/opt/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36m_prepare_for_python_RDD\u001b[0;34m(sc, command)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;31m# the serialized command will be compressed by broadcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCloudPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0mpickled_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickled_command\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 1M\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m         \u001b[0;31m# The broadcast will have same life cycle as created PythonRDD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/serializers.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    605\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Could not serialize object: %s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Could not serialize object: Py4JError: An error occurred while calling o32.__getstate__. Trace:\npy4j.Py4JException: Method __getstate__([]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:274)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\n"
     ]
    }
   ],
   "source": [
    "df3 = df1.withColumn(\"SalaryMixedFreq\",\n",
    "                     get_SalaryMixedFreq_udf(\n",
    "                         col('Salary Range From'),\n",
    "                         col('Salary Range To')\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1733.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 97.0 failed 4 times, most recent failure: Lost task 0.3 in stage 97.0 (TID 193, 172.19.0.4, executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 366, in main\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 241, in read_udfs\n    arg_offsets, udf = read_single_udf(pickleSer, infile, eval_type, runner_conf)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 168, in read_single_udf\n    f, return_type = read_command(pickleSer, infile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 69, in read_command\n    command = serializer._read_with_length(file)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 173, in _read_with_length\n    return self.loads(obj)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 587, in loads\n    return pickle.loads(obj, encoding=encoding)\nModuleNotFoundError: No module named 'utils'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:365)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3263)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3260)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3260)\n\tat sun.reflect.GeneratedMethodAccessor128.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 366, in main\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 241, in read_udfs\n    arg_offsets, udf = read_single_udf(pickleSer, infile, eval_type, runner_conf)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 168, in read_single_udf\n    f, return_type = read_command(pickleSer, infile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 69, in read_command\n    command = serializer._read_with_length(file)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 173, in _read_with_length\n    return self.loads(obj)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 587, in loads\n    return pickle.loads(obj, encoding=encoding)\nModuleNotFoundError: No module named 'utils'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-247-1bdb87f2de8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;31m# Below is toPandas without Arrow optimization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m         \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \"\"\"\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1733.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 97.0 failed 4 times, most recent failure: Lost task 0.3 in stage 97.0 (TID 193, 172.19.0.4, executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 366, in main\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 241, in read_udfs\n    arg_offsets, udf = read_single_udf(pickleSer, infile, eval_type, runner_conf)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 168, in read_single_udf\n    f, return_type = read_command(pickleSer, infile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 69, in read_command\n    command = serializer._read_with_length(file)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 173, in _read_with_length\n    return self.loads(obj)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 587, in loads\n    return pickle.loads(obj, encoding=encoding)\nModuleNotFoundError: No module named 'utils'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:365)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3263)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3260)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3260)\n\tat sun.reflect.GeneratedMethodAccessor128.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 366, in main\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 241, in read_udfs\n    arg_offsets, udf = read_single_udf(pickleSer, infile, eval_type, runner_conf)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 168, in read_single_udf\n    f, return_type = read_command(pickleSer, infile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 69, in read_command\n    command = serializer._read_with_length(file)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 173, in _read_with_length\n    return self.loads(obj)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 587, in loads\n    return pickle.loads(obj, encoding=encoding)\nModuleNotFoundError: No module named 'utils'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "df3.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
